{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8980e3-6a9f-4532-88ed-3b0aa158ad5d",
   "metadata": {},
   "source": [
    "# CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9f737-bd18-479d-bc6c-d18b3b940b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --topic='Food, Cafes and Restaurants' --concept_type='item' --mode='parallel'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96ed94a-8701-4dbf-9cfa-9a748a1a4c9f",
   "metadata": {},
   "source": [
    "# Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3144c83-705b-42aa-8488-d49c75eeb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import ParallelPipeline, SequentialPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61164e-99f0-44a2-bbc1-a385f802477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Home Interior and Lifestyle\"\n",
    "concept_type = 'item'\n",
    "full_pipeline = ParallelPipeline(topic, concept_type)\n",
    "full_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e88c1-f2d9-46f9-9f60-921b4f144f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Nature and ecology\"\n",
    "concept_type = 'item'\n",
    "full_pipeline = SequentialPipeline(topic, concept_type)\n",
    "full_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f67bac-10e0-49b9-8d8d-6cf79298c9b7",
   "metadata": {},
   "source": [
    "# Step by step usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d970eae-f587-47b9-b1d3-86aacf95fa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import update_config\n",
    "topic = \"Shopping and Retail\" #e.g. Sport, Fitness, and Tourism\n",
    "concept_type = \"item\" #e.g. interior\n",
    "update_config(topic, concept_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c1e2ac4-9a7e-42cc-b4ca-6512797f0acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /home/eugene/miniconda3/envs/myenv/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /home/eugene/miniconda3/envs/myenv/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 19:24:05.722585: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-06 19:24:05.755683: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-06 19:24:05.755710: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-06 19:24:05.755741: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-06 19:24:05.762665: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-06 19:24:06.507236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472ca5cadfdd4821ada8ab4b9d2924c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5584bfe6ed4cb887cdab89b54fb26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eugene/miniconda3/envs/myenv/lib/python3.9/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "[01.06.2024 19:24:36 | INFO]: Added lora lora/productDesign.safetensors.\n"
     ]
    }
   ],
   "source": [
    "from text_generators import get_llm\n",
    "from image_generator import get_pipe\n",
    "model, tokenizer = get_llm()\n",
    "pipe = get_pipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "412abd53-17f2-4638-8596-696b8199ee7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11dcb7660c294a1e930b4c68f9c70350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01.06.2024 19:51:50 | INFO]: Concepts saved to \"concepts/Shopping and Retail/item (Shopping and Retail).json\"\n"
     ]
    }
   ],
   "source": [
    "from text_generators import ConceptGenerator\n",
    "cg = ConceptGenerator(model, tokenizer)\n",
    "cg.generate(save=True, rewrite=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cb57776-35e3-424c-b3e2-39ed5064d0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4040ac9183da4923ace5f46a871daae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01.06.2024 20:04:22 | INFO]: Generated prompts saved to \"generated_prompts/Shopping and Retail/item (Shopping and Retail).json\"\n"
     ]
    }
   ],
   "source": [
    "from text_generators import PromptGenerator\n",
    "pg = PromptGenerator(model, tokenizer, batch_size=1)\n",
    "prompts = pg.generate(save=True, rewrite=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85471304-5089-4301-a6d7-aef7fbc00f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'too short': [], 'has intro': []}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from post_processor import PromptProcessor\n",
    "pp = PromptProcessor(prompt_generator=pg)\n",
    "regenerate, prompts = pp.process(save=True, auto_regenerate=True)\n",
    "regenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09462429-54db-4c07-b033-18950cc3dadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01.06.2024 20:04:42 | WARNING]: No negative prompt provided for Shopping and Retail item. Using default negative prompt for item.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608c8ad50b774af2a96e9efbdaa26908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (78 > 77). Running this sequence through the model will result in indexing errors\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['style']\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['style']\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['style']\n",
      "[01.06.2024 20:41:30 | INFO]: Saved to \"images/Shopping and Retail/item\"\n"
     ]
    }
   ],
   "source": [
    "from image_generator import ImageGenerator\n",
    "ig = ImageGenerator(pipe, batch_size=1)\n",
    "ig.generate(save=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8709a74-2f4d-45c8-9ab7-433c7501322c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fire_assistant_kernel",
   "language": "python",
   "name": "fire_assistant_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
